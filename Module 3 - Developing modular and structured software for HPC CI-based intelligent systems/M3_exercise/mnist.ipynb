{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Module 3: MNIST Exercise**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we’ve studied a bit of the theory and learned a few new concepts let's get some practical experience building a robust AI. Today, we’ll get started by constructing an intelligent system that can recognize one’s handwriting. \n",
    "\n",
    "As an introduction to AI programming, we have prepared a few basic functions that you can use to implement your very own Neural Network. You can import them via: \n",
    "\n",
    "Don't forget to install the necessary depedencies in the requirements.txt file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run import * \n",
    "from tensorflow.keras.datasets import mnist \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.layers import Flatten \n",
    "from tensorflow.keras.layers import Conv2D \n",
    "from tensorflow.keras.layers import MaxPooling2D \n",
    "from tensorflow.keras.optimizers import Adadelta \n",
    "from tensorflow.keras import utils \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, to make a robust AI we need a dataset with a sufficiently large number of observations. Luckily, there is a package in Tensorflow that provides a large dataset of images that are ready to be processed. Here we are pulling a dataset from the internet and the function takes care of processing the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = get_dataset(num_classes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create a Neural Network. Keras, a high-level API that acts as an interface for the TensorFlow library, makes building neural networks relatively easy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 14:37:04.860533: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = get_model(num_classes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at a few hyperparameters. These values can be adjusted to the performance of your model. \n",
    "\n",
    "A single epoch represents one full cycle through the training data and the learning rate dictates how much to change the model in response to the estimated error each time the model weights are updated. Num_classes represents how many different possible outputs there are. In this case, the 10 classes are images of digits 0 through 9. You can test with the hyperparameter settings above to see how your model performs and then change them to see if you can get better results. Give it a try. Note how the results vary depending on how many epochs you choose or what learning rate you choose.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 \n",
    "\n",
    "epochs = 5 \n",
    "\n",
    "num_classes = 10 \n",
    "\n",
    "verbose = 1 \n",
    "\n",
    "img_rows, img_cols = 28, 28 \n",
    "\n",
    "learning_rate=0.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to compile our model with an optimizer, you can learn more about optimizers here. but for now, just go with the Adadelta optimizer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adadelta(learning_rate=learning_rate) \n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now train and save your model with the code below. Here, Keras' fit function is optimized to such a degree that it will always use the highest number of available cores. This would be especially useful to us if we were running this on an HPC system.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.6068 - accuracy: 0.8154 - val_loss: 0.2222 - val_accuracy: 0.9343\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.3019 - accuracy: 0.9095 - val_loss: 0.1620 - val_accuracy: 0.9519\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.2369 - accuracy: 0.9302 - val_loss: 0.1182 - val_accuracy: 0.9659\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 74s 158ms/step - loss: 0.1855 - accuracy: 0.9454 - val_loss: 0.0940 - val_accuracy: 0.9704\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 63s 134ms/step - loss: 0.1519 - accuracy: 0.9555 - val_loss: 0.0788 - val_accuracy: 0.9757\n",
      "79/79 [==============================] - 2s 26ms/step - loss: 0.0788 - accuracy: 0.9757\n",
      "loss: 0.07879408448934555\n",
      "accuracy: 0.9757000207901001\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs, \n",
    "    verbose=verbose, \n",
    "    validation_data=(x_test, y_test)) \n",
    "\n",
    "model.save(\"test.h5\") \n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, y_test, batch_size=128) \n",
    "\n",
    "print(\"loss:\", loss) \n",
    "\n",
    "print(\"accuracy:\", accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, Keras' fit function is optimized to such a degree that it will always use the highest number of available cores. This would be especially useful to us if we were running this on an HPC system.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"test.h5\") \n",
    "img = Image.open(r'path/to/test_image/here.png').convert(\"L\") \n",
    "img = np.resize(img, (img_rows, img_cols)) \n",
    "im2arr = np.array(img) \n",
    "im2arr = im2arr.reshape(1,img_rows, img_cols,1) \n",
    "im2arr = im2arr / 255  \n",
    "\n",
    "yh = np.argmax(model.predict(im2arr.reshape(1,img_rows, img_cols,1)), axis=-1) \n",
    "\n",
    "print(yh) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final remaining task is to make a 28x28 black filled canvas and then painting your own number to test your model. I recommend a brush of 4 pixels to draw your number.\n",
    "\n",
    "Congratulations!! You have just made your very own Neural Network that can predict your handwritten digits.  \n",
    "\n",
    "The code design was inspired by the databricks design[7].  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "\n",
    "[1] https://cloud.google.com/responsible-ai#section-2 \n",
    "\n",
    "[2] https://www.microsoft.com/en-us/research/uploads/prod/2019/03/amershi-icse-2019_Software_Engineering_for_Machine_Learning.pdf \n",
    "\n",
    "[3] https://arxiv.org/pdf/1808.01664.pdf \n",
    "\n",
    "[4] http://art360.mybluemix.net/?_ga=2.265458054.825521404.1626898609-440520872.1626560578 \n",
    "\n",
    "[5]https://medium.com/dataswati-garage/create-a-robust-ai-rest-api-71a8050ce314 \n",
    "\n",
    "[6] http://www.r-5.org/files/books/computers/algo-list/common/Heineman_Pollice_Selkow-Algorithms_in_a_Nutshell-EN.pdf \n",
    "\n",
    "[7] https://docs.databricks.com/_static/notebooks/deep-learning/mnist-tensorflow-keras.html \n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit (conda)",
   "name": "python3811jvsc74a57bd0ee42e640ef3d96445434b084285692c6dda5db3d72d0d4ac702126b500b29cbf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "metadata": {
   "interpreter": {
    "hash": "ee42e640ef3d96445434b084285692c6dda5db3d72d0d4ac702126b500b29cbf"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}